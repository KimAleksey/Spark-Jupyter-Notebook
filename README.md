# Проект: Обучение Spark с использованием Jupyter Notebook

Этот проект предназначен для изучения основ Apache Spark и работы с данными (PySpark) в интерактивной среде Jupyter.

## Структура проекта

- `work/`: Рабочая директория с блокнотами.
  - `First-notebook.ipynb`: Введение в Spark, создание сессии и базовые операции с DataFrame.
  - `2-Working-with-data.ipynb`: Глубокое погружение в работу с данными на примере датасета такси Нью-Йорка (NYC Taxi). Включает фильтрацию, агрегацию, оконные функции и Spark SQL.
- `docker-compose.yaml`: Конфигурация Docker для быстрого запуска среды со всеми зависимостями.

## Как запустить

1. **Запуск контейнера:**
   ```bash
   docker-compose up -d
   ```

2. **Доступ к Jupyter Lab:**
   Откройте браузер и перейдите по адресу `http://localhost:8888`. Токен для входа можно найти в логах контейнера (`docker logs spark-jupyter`).

3. **Spark UI:**
   После инициализации `SparkSession` в любом из блокнотов, интерфейс Spark UI будет доступен по адресу `http://localhost:4040`.

## Что вы изучите

- Инициализация и настройка `SparkSession`.
- Чтение и запись данных в форматах Parquet и CSV.
- Трансформации DataFrame: `select`, `filter`, `withColumn`, `drop`.
- Аггрегации и группировки данных.
- Использование оконных функций (`Window functions`).
- Выполнение SQL запросов напрямую к данным через Spark SQL.
- Обработка пропусков (NULL значений).

## Технологический стек

- **Spark 3.5.0**
- **Python 3.11**
- **JupyterLab**
- **Docker**
