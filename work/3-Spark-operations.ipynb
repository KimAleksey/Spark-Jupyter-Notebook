{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71f2b0f-1380-4675-a391-83fde86ebe2a",
   "metadata": {},
   "source": [
    "### Инофрмация о датасете\n",
    "\n",
    "https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a3ffcc-2362-4b08-92d7-204d8a6f3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем либы\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628a9ca9-0754-4532-8aa0-ff71e4848c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем сессию\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"Basics-operations\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f289bce-8f9b-4de4-99da-93164054b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "\n",
    "df = spark.read.parquet(\"data/nyc_taxi/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29e8a44b-a14c-4f3b-8f8a-754f7bbb5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+--------------------+------------------+------------------+\n",
      "|summary|          VendorID|   passenger_count|    trip_distance|        RatecodeID|store_and_fwd_flag|     PULocationID|     DOLocationID|      payment_type|       fare_amount|            extra|           mta_tax|        tip_amount|       tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        airport_fee|            filename|              year|             month|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+--------------------+------------------+------------------+\n",
      "|  count|          91534087|          88010143|         91534087|          88010143|          88010143|         91534087|         91534087|          91534087|          91534087|         91534087|          91534087|          91534087|           91534087|             91534087|          91534087|            88010143|           60008316|            91534087|          91534087|          91534087|\n",
      "|   mean| 1.708678833492926| 1.428714176728471|5.619699563945162|1.2102355406921677|              NULL|164.6217173936525|162.1061025058348|1.2027911634711559|11.851000785429665|1.039220191599213|0.4965007297226923|4.3707370204187725|0.42271025590903366|   0.3055509681571104| 20.10627028678565|   2.281249860030338|0.08628948611055841|                NULL|2021.1237964497313|6.1685337507108144|\n",
      "| stddev|0.5052436615330742|1.0303576731588777| 576.349877543242| 3.845563647773475|              NULL|66.07312463944142| 70.6267153913583|0.5254503527286332|14697.734918211156|52.27615814792112| 52.26117154599526|14696.537497737565| 1.8547135730599151|  0.09034956594190459|214.53270090712928|  0.7427551322149569|0.31961664408713664|                NULL| 0.804393077956162| 3.639117109493967|\n",
      "|    min|                 1|               0.0|           -30.62|               1.0|                 N|                1|                1|                 0|     -1.33391414E8|            -27.0|             -0.55|           -493.22|             -99.99|                 -1.0|           -2567.8|                -2.5|              -1.25|file:///home/jovy...|              2020|                 1|\n",
      "|    max|                 6|             112.0|        357192.65|              99.0|                 Y|              265|              265|                 5|         998310.03|         500000.8|          500000.5|    1.3339136353E8|             956.55|                  1.0|         1000003.8|                 3.0|               1.25|file:///home/jovy...|              2022|                12|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Информация о полях DataFrame\n",
    "\n",
    "# The describe() function in Spark is used to compute summary statistics for numerical and string columns in a DataFrame. \n",
    "# It provides a quick way to understand the distribution of data, including count, mean, standard deviation, minimum, and maximum values. \n",
    "# This is particularly useful for exploratory data analysis (EDA) and data profiling.\n",
    "\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "148207c8-c75d-4f68-be33-f2ca3eca8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Информация о schema\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860c633-fba9-4e45-92d0-b07ffd71c566",
   "metadata": {},
   "source": [
    "### SELECT — выбор колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6125602-2df1-4636-aa7d-1812ed581ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|VendorID|trip_distance|\n",
      "+--------+-------------+\n",
      "|       1|          1.2|\n",
      "|       1|          0.4|\n",
      "|       1|          1.2|\n",
      "|       1|          1.1|\n",
      "|       1|          0.6|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT \"VendorID\", \"trip_distance\" FROM df;\n",
    "\n",
    "df.select(\"VendorID\", \"trip_distance\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e188f1-cc3b-4365-b083-6c29f36352f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " VendorID              | 1                    \n",
      " tpep_pickup_datetime  | 2020-01-01 00:28:15  \n",
      " tpep_dropoff_datetime | 2020-01-01 00:33:03  \n",
      " passenger_count       | 1.0                  \n",
      " trip_distance         | 1.2                  \n",
      " RatecodeID            | 1.0                  \n",
      " store_and_fwd_flag    | N                    \n",
      " PULocationID          | 238                  \n",
      " DOLocationID          | 239                  \n",
      " payment_type          | 1                    \n",
      " fare_amount           | 6.0                  \n",
      " extra                 | 3.0                  \n",
      " mta_tax               | 0.5                  \n",
      " tip_amount            | 1.47                 \n",
      " tolls_amount          | 0.0                  \n",
      " improvement_surcharge | 0.3                  \n",
      " total_amount          | 11.27                \n",
      " congestion_surcharge  | 2.5                  \n",
      " airport_fee           | NULL                 \n",
      " filename              | file:///home/jovy... \n",
      " year                  | 2020                 \n",
      " month                 | 1                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT * FROM df;\n",
    "\n",
    "df.select(\"*\").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cffb14e6-7a7f-4b1b-b7b1-b56610411643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Использование расчетов F.col\n",
    "# SELECT\n",
    "#     VendorID,\n",
    "#     ROUND(total_amount / 1000, 2) AS total_amount\n",
    "# FROM trips\n",
    "\n",
    "df.select(F.col(\"VendorID\"), F.round(F.col(\"total_amount\")/1000,2).alias(\"total_amount\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a429e6af-cd85-4f72-bedb-506b9c350a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|payment_method|\n",
      "+--------------+\n",
      "|          Cash|\n",
      "|   Credit card|\n",
      "|       Dispute|\n",
      "|Flex Fare trip|\n",
      "|     No charge|\n",
      "|       Unknown|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distinct, Case, Order By, Alias\n",
    "\n",
    "(\n",
    "    df\n",
    "    .select(\"payment_type\")\n",
    "    .distinct()\n",
    "    .orderBy(\"payment_type\")\n",
    "    .select(\n",
    "        F\n",
    "        .when(df['payment_type'] == 0, 'Flex Fare trip')\n",
    "        .when(df['payment_type'] == 1, 'Credit card')\n",
    "        .when(df['payment_type'] == 2, 'Cash')\n",
    "        .when(df['payment_type'] == 3, 'No charge')\n",
    "        .when(df['payment_type'] == 4, 'Dispute')\n",
    "        .when(df['payment_type'] == 5, 'Unknown')\n",
    "        .when(df['payment_type'] == 6, 'Voided trip')\n",
    "        .otherwise('Unknown')\n",
    "        .alias(\"payment_method\")\n",
    "    )\n",
    "    .orderBy(\"payment_method\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a64cf69-7512-4219-93f5-d03db4f3c3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL\n",
    "\n",
    "df.createOrReplaceTempView(\"trips\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        VendorID,\n",
    "        ROUND(total_amount / 1000, 2) AS total_amount\n",
    "    FROM trips\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84618922-40a6-4b0e-b0ec-6db971949e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|payment_type|\n",
      "+------------+\n",
      "|           0|\n",
      "|           1|\n",
      "|           2|\n",
      "|           3|\n",
      "|           4|\n",
      "|           5|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Можно продолжить использовать trips в других ячейках\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        payment_type\n",
    "    FROM trips\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d125ade0-8369-4833-b1be-c311c9068785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|VendorID|Literal|\n",
      "+--------+-------+\n",
      "|       1|Literal|\n",
      "|       5|Literal|\n",
      "|       2|Literal|\n",
      "|       6|Literal|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lit - Констранта\n",
    "\n",
    "# The lit() function in Spark is used to create a new column with a constant or literal value. \n",
    "# It is part of the pyspark.sql.functions module and is particularly useful when you need to add a column with a fixed value to a DataFrame. \n",
    "# This function is often used in combination with other transformations, such as withColumn().\n",
    "\n",
    "df.select(\"VendorID\", F.lit('Literal')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff5eae-2368-4549-a1b3-d5933681db11",
   "metadata": {},
   "source": [
    "### SELECT EXPR - Использование SQL выражений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b8b1202-d608-403b-aea1-4e86489e4746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "|       1|        0.01|\n",
      "+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Перечисление полей\n",
    "\n",
    "df.selectExpr(\"VendorID\", \"ROUND(total_amount / 1000, 2) AS total_amount\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd4d745c-6e7c-47ab-8794-a9b6b018fc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------------+\n",
      "|VendorID|text                             |\n",
      "+--------+---------------------------------+\n",
      "|1       |Creative Mobile Technologies, LLC|\n",
      "|2       |Curb Mobility, LLC               |\n",
      "|5       |Unknown                          |\n",
      "|6       |Myle Technologies Inc            |\n",
      "+--------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CASE\n",
    "\n",
    "(\n",
    "    df\n",
    "    .select(\"VendorID\")\n",
    "    .distinct()\n",
    "    .selectExpr(\"VendorID\",\n",
    "    \"\"\"\n",
    "        CASE \n",
    "            WHEN VendorID = 1 THEN 'Creative Mobile Technologies, LLC'\n",
    "            WHEN VendorID = 2 THEN 'Curb Mobility, LLC'\n",
    "            WHEN VendorID = 6 THEN 'Myle Technologies Inc'\n",
    "            WHEN VendorID = 7 THEN 'Helix'\n",
    "            ELSE 'Unknown' \n",
    "        END AS text\n",
    "    \"\"\")\n",
    "    .orderBy(\"VendorID\")\n",
    "    .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3e5a884-9e30-4d5a-ac28-f5e64ece703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+\n",
      "| avg_total_amount|max_total_amount|min_total_amount|\n",
      "+-----------------+----------------+----------------+\n",
      "|20.10627028678565|       1000003.8|         -2567.8|\n",
      "+-----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AGGR\n",
    "\n",
    "df\\\n",
    ".selectExpr(\n",
    "    \"AVG(total_amount) AS avg_total_amount\", \n",
    "    \"MAX(total_amount) AS max_total_amount\", \n",
    "    \"MIN(total_amount) AS min_total_amount\"\n",
    ")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c6760-8081-4896-8c83-b68fd775b997",
   "metadata": {},
   "source": [
    "### COL\n",
    "\n",
    "The col() function in Spark is used to reference a column in a DataFrame. \n",
    "\n",
    "It is part of the pyspark.sql.functions module and is commonly used in DataFrame transformations, such as filtering, sorting, and aggregations. \n",
    "\n",
    "The col() function allows you to refer to columns dynamically and is particularly useful when working with complex expressions or when column names are stored in variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3245421-7873-4939-bc4f-d7b3df282c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " VendorID              | 1                    \n",
      " tpep_pickup_datetime  | 2020-01-01 00:28:15  \n",
      " tpep_dropoff_datetime | 2020-01-01 00:33:03  \n",
      " passenger_count       | 1.0                  \n",
      " trip_distance         | 1.2                  \n",
      " RatecodeID            | 1.0                  \n",
      " store_and_fwd_flag    | N                    \n",
      " PULocationID          | 238                  \n",
      " DOLocationID          | 239                  \n",
      " payment_type          | 1                    \n",
      " fare_amount           | 6.0                  \n",
      " extra                 | 3.0                  \n",
      " mta_tax               | 0.5                  \n",
      " tip_amount            | 1.47                 \n",
      " tolls_amount          | 0.0                  \n",
      " improvement_surcharge | 0.3                  \n",
      " total_amount          | 11.27                \n",
      " congestion_surcharge  | 2.5                  \n",
      " airport_fee           | NULL                 \n",
      " filename              | file:///home/jovy... \n",
      " year                  | 2020                 \n",
      " month                 | 1                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Referencing a Column in a Filter Operation\n",
    "\n",
    "df.filter(F.col(\"VendorID\") == 1).show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e988ab83-b673-4b9a-b779-5ff9df391d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " VendorID              | 2                    \n",
      " tpep_pickup_datetime  | 2020-01-28 19:19:36  \n",
      " tpep_dropoff_datetime | 2020-01-28 19:50:40  \n",
      " passenger_count       | 1.0                  \n",
      " trip_distance         | 17.59                \n",
      " RatecodeID            | 2.0                  \n",
      " store_and_fwd_flag    | N                    \n",
      " PULocationID          | 132                  \n",
      " DOLocationID          | 215                  \n",
      " payment_type          | 1                    \n",
      " fare_amount           | 52.0                 \n",
      " extra                 | 4.5                  \n",
      " mta_tax               | 0.5                  \n",
      " tip_amount            | 12.68                \n",
      " tolls_amount          | 6.12                 \n",
      " improvement_surcharge | 0.3                  \n",
      " total_amount          | 76.1                 \n",
      " congestion_surcharge  | 0.0                  \n",
      " airport_fee           | NULL                 \n",
      " filename              | file:///home/jovy... \n",
      " year                  | 2020                 \n",
      " month                 | 1                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(F.col(\"total_amount\") > 30).show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa3eee4e-3ee9-486f-a499-e955eed328c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|VendorID|total_amnt|\n",
      "+--------+----------+\n",
      "|       1|     11.27|\n",
      "|       1|      8.74|\n",
      "|       1|      12.3|\n",
      "|       1|     12.25|\n",
      "|       1|      10.8|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Referencing a Column in a Select Operation\n",
    "\n",
    "df.select(F.col(\"VendorID\"), F.col(\"total_amount\").alias('total_amnt')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "37b33c6f-dc6f-4082-b81f-ed38bd1f8458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|payment_type|        total_amount|\n",
      "+------------+--------------------+\n",
      "|           0| 1.092547517000018E8|\n",
      "|           1|1.3924048912388363E9|\n",
      "|           2|3.3062123700528276E8|\n",
      "|           3|   8246323.020001265|\n",
      "|           4| -118468.51000007371|\n",
      "|           5|   359.2700000000001|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using col() in Aggregations\n",
    "\n",
    "df.groupBy(F.col(\"payment_type\")).agg(F.sum(F.col(\"total_amount\")).alias('total_amount')).orderBy(\"payment_type\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "00f29ee9-18f7-42af-9a2a-cbaffad77f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " VendorID              | 1                    \n",
      " tpep_pickup_datetime  | 2020-01-01 00:28:15  \n",
      " tpep_dropoff_datetime | 2020-01-01 00:33:03  \n",
      " passenger_count       | 1.0                  \n",
      " trip_distance         | 1.2                  \n",
      " RatecodeID            | 1.0                  \n",
      " store_and_fwd_flag    | N                    \n",
      " PULocationID          | 238                  \n",
      " DOLocationID          | 239                  \n",
      " payment_type          | 1                    \n",
      " fare_amount           | 6.0                  \n",
      " extra                 | 3.0                  \n",
      " mta_tax               | 0.5                  \n",
      " tip_amount            | 1.47                 \n",
      " tolls_amount          | 0.0                  \n",
      " improvement_surcharge | 0.3                  \n",
      " total_amount          | 11.27                \n",
      " congestion_surcharge  | 2.5                  \n",
      " airport_fee           | NULL                 \n",
      " filename              | file:///home/jovy... \n",
      " year                  | 2020                 \n",
      " month                 | 1                    \n",
      " AgeGroup              | Low                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using col() with Conditional Logic\n",
    "\n",
    "df.withColumn(\n",
    "    \"AgeGroup\", \n",
    "    F.when(F.col(\"total_amount\") < 30, \"Low\")\n",
    "    .otherwise(\"High\")\n",
    ").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "01480b10-a597-4b81-ab6e-849da829bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------------+\n",
      "|VendorID|total_amount|       amount_rub|\n",
      "+--------+------------+-----------------+\n",
      "|       1|       11.27|957.9499999999999|\n",
      "|       1|        8.74|            742.9|\n",
      "|       1|        12.3|           1045.5|\n",
      "|       1|       12.25|          1041.25|\n",
      "|       1|        10.8|918.0000000000001|\n",
      "+--------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using col() with Mathematical Operations\n",
    "\n",
    "df.withColumn(\"amount_rub\", F.col(\"total_amount\") * 85).select(\"VendorID\", \"total_amount\", \"amount_rub\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5741a26-2429-40e3-9990-fbf631f17420",
   "metadata": {},
   "source": [
    "### COLUMNS\n",
    "\n",
    "The columns attribute in Spark is used to retrieve the list of column names in a DataFrame. \n",
    "\n",
    "It provides a quick and easy way to inspect the structure of the DataFrame and access the names of all columns. \n",
    "\n",
    "This is particularly useful for debugging, data exploration, and dynamic column access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a52394c-ddec-4a2c-a151-3b70e9ebe68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'airport_fee',\n",
       " 'filename',\n",
       " 'year',\n",
       " 'month']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98d38bc8-122d-4b5b-8fa2-68eeef04dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: VendorID, Data Type: LongType()\n",
      "Column: tpep_pickup_datetime, Data Type: TimestampNTZType()\n",
      "Column: tpep_dropoff_datetime, Data Type: TimestampNTZType()\n",
      "Column: passenger_count, Data Type: DoubleType()\n",
      "Column: trip_distance, Data Type: DoubleType()\n",
      "Column: RatecodeID, Data Type: DoubleType()\n",
      "Column: store_and_fwd_flag, Data Type: StringType()\n",
      "Column: PULocationID, Data Type: LongType()\n",
      "Column: DOLocationID, Data Type: LongType()\n",
      "Column: payment_type, Data Type: LongType()\n",
      "Column: fare_amount, Data Type: DoubleType()\n",
      "Column: extra, Data Type: DoubleType()\n",
      "Column: mta_tax, Data Type: DoubleType()\n",
      "Column: tip_amount, Data Type: DoubleType()\n",
      "Column: tolls_amount, Data Type: DoubleType()\n",
      "Column: improvement_surcharge, Data Type: DoubleType()\n",
      "Column: total_amount, Data Type: DoubleType()\n",
      "Column: congestion_surcharge, Data Type: DoubleType()\n",
      "Column: airport_fee, Data Type: DoubleType()\n",
      "Column: filename, Data Type: StringType()\n",
      "Column: year, Data Type: IntegerType()\n",
      "Column: month, Data Type: IntegerType()\n"
     ]
    }
   ],
   "source": [
    "# Access columns dynamically\n",
    "\n",
    "for column in df.columns:\n",
    "    print(f\"Column: {column}, Data Type: {df.schema[column].dataType}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869da267-24f9-4aa8-b64a-f256fa4d2c90",
   "metadata": {},
   "source": [
    "### DTYPES\n",
    "\n",
    "The dtypes attribute in Spark is used to retrieve the schema of a DataFrame in the form of a list of tuples.\n",
    "\n",
    "Each tuple contains the column name and its corresponding data type. \n",
    "\n",
    "This is particularly useful for inspecting the structure of the data and understanding the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "12078fd9-e5bb-4d54-a393-a5e4374022b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VendorID', 'bigint'),\n",
       " ('tpep_pickup_datetime', 'timestamp_ntz'),\n",
       " ('tpep_dropoff_datetime', 'timestamp_ntz'),\n",
       " ('passenger_count', 'double'),\n",
       " ('trip_distance', 'double'),\n",
       " ('RatecodeID', 'double'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('PULocationID', 'bigint'),\n",
       " ('DOLocationID', 'bigint'),\n",
       " ('payment_type', 'bigint'),\n",
       " ('fare_amount', 'double'),\n",
       " ('extra', 'double'),\n",
       " ('mta_tax', 'double'),\n",
       " ('tip_amount', 'double'),\n",
       " ('tolls_amount', 'double'),\n",
       " ('improvement_surcharge', 'double'),\n",
       " ('total_amount', 'double'),\n",
       " ('congestion_surcharge', 'double'),\n",
       " ('airport_fee', 'double'),\n",
       " ('filename', 'string'),\n",
       " ('year', 'int'),\n",
       " ('month', 'int')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61036f-caa1-4b0e-bee3-890fc5268607",
   "metadata": {},
   "source": [
    "### printSchema\n",
    "\n",
    "The printSchema() function in Spark is used to display the schema of a DataFrame or Dataset. \n",
    "\n",
    "It provides a tree-like structure that shows the column names, data types, and whether the columns are nullable. \n",
    "\n",
    "This is particularly useful for understanding the structure of the data and debugging schema-related issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a0f18968-85f5-4063-9a6f-e58317191ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750bc95-0b3e-4152-a312-6912372094c8",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "The explain() function in Spark is used to display the execution plan of a DataFrame or Dataset operation. \n",
    "\n",
    "It provides detailed information about how Spark will execute a query, including the logical and physical plans. \n",
    "\n",
    "This is particularly useful for debugging, optimizing performance, and understanding the underlying execution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82b9bdf4-20c9-4959-b9fe-a9dc01e99e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Relation [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "VendorID: bigint, tpep_pickup_datetime: timestamp_ntz, tpep_dropoff_datetime: timestamp_ntz, passenger_count: double, trip_distance: double, RatecodeID: double, store_and_fwd_flag: string, PULocationID: bigint, DOLocationID: bigint, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, airport_fee: double, filename: string, year: int, month: int\n",
      "Relation [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Relation [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] parquet\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) ColumnarToRow\n",
      "+- FileScan parquet [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/data/nyc_taxi], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<VendorID:bigint,tpep_pickup_datetime:timestamp_ntz,tpep_dropoff_datetime:timestamp_ntz,pas...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain(mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d6686d05-bff8-43f1-a647-aa272297b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter ('total_amount > 100)\n",
      "+- Relation [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "VendorID: bigint, tpep_pickup_datetime: timestamp_ntz, tpep_dropoff_datetime: timestamp_ntz, passenger_count: double, trip_distance: double, RatecodeID: double, store_and_fwd_flag: string, PULocationID: bigint, DOLocationID: bigint, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, airport_fee: double, filename: string, year: int, month: int\n",
      "Filter (total_amount#60 > cast(100 as double))\n",
      "+- Relation [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(total_amount#60) AND (total_amount#60 > 100.0))\n",
      "+- Relation [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] parquet\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(total_amount#60) AND (total_amount#60 > 100.0))\n",
      "+- *(1) ColumnarToRow\n",
      "   +- FileScan parquet [VendorID#44L,tpep_pickup_datetime#45,tpep_dropoff_datetime#46,passenger_count#47,trip_distance#48,RatecodeID#49,store_and_fwd_flag#50,PULocationID#51L,DOLocationID#52L,payment_type#53L,fare_amount#54,extra#55,mta_tax#56,tip_amount#57,tolls_amount#58,improvement_surcharge#59,total_amount#60,congestion_surcharge#61,airport_fee#62,filename#63,year#64,month#65] Batched: true, DataFilters: [isnotnull(total_amount#60), (total_amount#60 > 100.0)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/data/nyc_taxi], PartitionFilters: [], PushedFilters: [IsNotNull(total_amount), GreaterThan(total_amount,100.0)], ReadSchema: struct<VendorID:bigint,tpep_pickup_datetime:timestamp_ntz,tpep_dropoff_datetime:timestamp_ntz,pas...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"total_amount > 100\").explain(mode=\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5544ff5-79d0-4070-aa29-1e47077ea7c0",
   "metadata": {},
   "source": [
    "### DROP\n",
    "\n",
    "The drop() command in Spark is used to remove one or more columns from a DataFrame. \n",
    "\n",
    "This is particularly useful when you need to clean up your dataset by removing unnecessary or redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3b43dfba-2597-4f34-97a4-cb3b4092c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|VendorID|\n",
      "+--------+\n",
      "|       1|\n",
      "|       1|\n",
      "|       1|\n",
      "|       1|\n",
      "|       1|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"VendorID\", \"total_amount\").drop(\"total_amount\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e80229f4-88d7-4c4b-8853-5a506da1cd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------\n",
      " passenger_count       | 1.0  \n",
      " trip_distance         | 1.2  \n",
      " RatecodeID            | 1.0  \n",
      " PULocationID          | 238  \n",
      " DOLocationID          | 239  \n",
      " payment_type          | 1    \n",
      " fare_amount           | 6.0  \n",
      " extra                 | 3.0  \n",
      " mta_tax               | 0.5  \n",
      " tip_amount            | 1.47 \n",
      " tolls_amount          | 0.0  \n",
      " improvement_surcharge | 0.3  \n",
      " congestion_surcharge  | 2.5  \n",
      " airport_fee           | NULL \n",
      " year                  | 2020 \n",
      " month                 | 1    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns using a list\n",
    "\n",
    "columns_to_drop = [\"VendorID\", \"total_amount\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"filename\", \"store_and_fwd_flag\"]\n",
    "df_dropped = df.drop(*columns_to_drop)\n",
    "df_dropped.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9fc3c-6166-49c5-8720-936fe1437464",
   "metadata": {},
   "source": [
    "### Spark: dropDuplicates function\n",
    "\n",
    "The dropDuplicates() command in Spark is used to remove duplicate rows from a DataFrame. \n",
    "\n",
    "It is similar to the distinct() command but provides more flexibility by allowing you to specify a subset of columns to consider when identifying duplicates. \n",
    "\n",
    "This is particularly useful when you want to remove duplicates based on specific columns rather than the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1031bcba-bfb1-4673-8a61-fd999f1b74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " VendorID              | 2                    \n",
      " tpep_pickup_datetime  | 2020-01-01 11:23:55  \n",
      " tpep_dropoff_datetime | 2020-01-01 11:52:55  \n",
      " passenger_count       | 1.0                  \n",
      " trip_distance         | 13.87                \n",
      " RatecodeID            | 3.0                  \n",
      " store_and_fwd_flag    | N                    \n",
      " PULocationID          | 13                   \n",
      " DOLocationID          | 1                    \n",
      " payment_type          | 2                    \n",
      " fare_amount           | 57.0                 \n",
      " extra                 | 0.0                  \n",
      " mta_tax               | 0.0                  \n",
      " tip_amount            | 0.0                  \n",
      " tolls_amount          | 10.5                 \n",
      " improvement_surcharge | 0.3                  \n",
      " total_amount          | 67.8                 \n",
      " congestion_surcharge  | 0.0                  \n",
      " airport_fee           | NULL                 \n",
      " filename              | file:///home/jovy... \n",
      " year                  | 2020                 \n",
      " month                 | 1                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((F.col(\"year\") == 2020) & (F.col(\"month\") == 1)).dropDuplicates().show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb123a1d-2d80-40a9-8180-ba0ec504a084",
   "metadata": {},
   "source": [
    "### Spark: filter or where function\n",
    "\n",
    "The filter() or where() command in Spark is used to filter rows from a DataFrame based on a specified condition. \n",
    "\n",
    "Both filter() and where() are interchangeable and can be used to achieve the same result. \n",
    "\n",
    "The primary purpose of these commands is to select a subset of rows that meet a given condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d05ebf0a-8b4c-4ca9-bb45-d2ee3e9ffb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|VendorID|\n",
      "+--------+\n",
      "|       5|\n",
      "|       1|\n",
      "|       2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WHERE\n",
    "\n",
    "df.select(\"VendorID\").filter(\"year = 2020 and month = 1\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9154e2f6-5407-43b7-98ca-83d9a66cc323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|VendorID|\n",
      "+--------+\n",
      "|       5|\n",
      "|       1|\n",
      "|       2|\n",
      "|       6|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"VendorID\").filter(F.col(\"year\") == 2020).distinct().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
